{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "\n",
    "class BannerReplacer(ABC):\n",
    "    @abstractmethod\n",
    "    def build_model(self, filename):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def detect_banner(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def insert_logo(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class UnetLogoInsertion(BannerReplacer):\n",
    "    \n",
    "    '''\n",
    "    The model detects banner and replace it with other logo using Unet neural network model\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, frame, logo):\n",
    "        self.model = None\n",
    "        self.detected_mask = None\n",
    "        self.frame = frame\n",
    "        self.logo = logo\n",
    "    \n",
    "    \n",
    "    def build_model(self, model_weights_path, img_height, img_width, img_channels):\n",
    "        \n",
    "        '''\n",
    "        This method builds Unet neural network model and load trained weights\n",
    "        :model_weights_path: the path to the saved weights for the model\n",
    "        :img_width: width of the input image for training\n",
    "        :img_height: height of the input image for training\n",
    "        :img_channels: number of channels in input image\n",
    "        '''\n",
    "\n",
    "        inputs = tf.keras.layers.Input((img_width, img_height, img_channels))\n",
    "\n",
    "        # CONTRACTION PATH\n",
    "\n",
    "        c1 = tf.keras.layers.Conv2D(16, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(inputs)\n",
    "        c1 = tf.keras.layers.Conv2D(16, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n",
    "        p1 = tf.keras.layers.MaxPooling2D((2,2))(c1)\n",
    "        p1 = tf.keras.layers.Dropout(0.2)(p1)\n",
    "\n",
    "        c2 = tf.keras.layers.Conv2D(32, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n",
    "        c2 = tf.keras.layers.Conv2D(32, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n",
    "        p2 = tf.keras.layers.MaxPooling2D((2,2))(c2)\n",
    "        p2 = tf.keras.layers.Dropout(0.2)(p2)\n",
    "\n",
    "        c3 = tf.keras.layers.Conv2D(64, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n",
    "        c3 = tf.keras.layers.Conv2D(64, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n",
    "        p3 = tf.keras.layers.MaxPooling2D((2,2))(c3)\n",
    "        p3 = tf.keras.layers.Dropout(0.2)(p3)\n",
    "\n",
    "        c4 = tf.keras.layers.Conv2D(128, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n",
    "        c4 = tf.keras.layers.Conv2D(128, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n",
    "        p4 = tf.keras.layers.MaxPooling2D((2,2))(c4)\n",
    "        p4 = tf.keras.layers.Dropout(0.2)(p4)\n",
    "\n",
    "        c5 = tf.keras.layers.Conv2D(256, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n",
    "        c5 = tf.keras.layers.Conv2D(256, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
    "\n",
    "\n",
    "\n",
    "        # EXPANSIVE PATH\n",
    "\n",
    "\n",
    "        u6 = tf.keras.layers.Conv2DTranspose(128, (2,2), strides=(2,2), padding='same')(c5)\n",
    "        u6 = tf.keras.layers.concatenate([u6, c4])\n",
    "        u6 = tf.keras.layers.Dropout(0.2)(u6)\n",
    "        c6 = tf.keras.layers.Conv2D(128, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n",
    "        c6 = tf.keras.layers.Conv2D(128, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n",
    "\n",
    "        u7 = tf.keras.layers.Conv2DTranspose(64, (2,2), strides=(2,2), padding='same')(c6)\n",
    "        u7 = tf.keras.layers.concatenate([u7, c3])\n",
    "        u7 = tf.keras.layers.Dropout(0.2)(u7)\n",
    "        c7 = tf.keras.layers.Conv2D(64, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n",
    "        c7 = tf.keras.layers.Conv2D(64, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n",
    "\n",
    "        u8 = tf.keras.layers.Conv2DTranspose(32, (2,2), strides=(2,2), padding='same')(c7)\n",
    "        u8 = tf.keras.layers.concatenate([u8, c2])\n",
    "        u8 = tf.keras.layers.Dropout(0.2)(u8)\n",
    "        c8 = tf.keras.layers.Conv2D(32, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n",
    "        c8 = tf.keras.layers.Conv2D(32, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n",
    "\n",
    "        u9 = tf.keras.layers.Conv2DTranspose(16, (2,2), strides=(2,2), padding='same')(c8)\n",
    "        u9 = tf.keras.layers.concatenate([u9, c1], axis=3)\n",
    "        u9 = tf.keras.layers.Dropout(0.2)(u9)\n",
    "        c9 = tf.keras.layers.Conv2D(16, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n",
    "        c9 = tf.keras.layers.Conv2D(16, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n",
    "\n",
    "        outputs = tf.keras.layers.Conv2D(1, (1,1), activation='sigmoid')(c9)\n",
    "\n",
    "        self.model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
    "        \n",
    "        self.model.compile(optimizer='adam', loss=self.__loss, metrics=[self.__dice_coef])\n",
    "        \n",
    "        # load trained model weights\n",
    "        self.model.load_weights(model_weights_path)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    def detect_banner(self):\n",
    "        \n",
    "        # getting full size predicted mask of the frame\n",
    "        fsz_mask = self.__predict_full_size(img_height=256, img_width=256)\n",
    "        \n",
    "        fsz_mask = (fsz_mask > 0.95).astype(np.uint8)\n",
    "        \n",
    "        # looking for contours\n",
    "        first_cnt = True\n",
    "        min_x_max_y =[] \n",
    "        max_x_min_y =[]\n",
    "\n",
    "        _, thresh = cv2.threshold(fsz_mask, 0.5, 255, 0)\n",
    "\n",
    "        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        for cnt in contours:\n",
    "            if cv2.contourArea(cnt) > 30:\n",
    "                \n",
    "                # works for the first contour\n",
    "                if first_cnt:\n",
    "                    x_top_left = cnt[:,0,0].min() \n",
    "                    x_bot_right = cnt[:,0,0].max()\n",
    "                    y_top_left = cnt[:,0,1].min() \n",
    "                    y_bot_right = cnt[:,0,1].max()\n",
    "\n",
    "                    first_cnt = False\n",
    "                \n",
    "                # works with more than one contour\n",
    "                else:\n",
    "                    new_x_top_left = cnt[:,0,0].min() \n",
    "                    if new_x_top_left < x_top_left:\n",
    "                        x_top_left = new_x_top_left\n",
    "\n",
    "                    new_x_bot_right = cnt[:,0,0].max()\n",
    "                    if new_x_bot_right > x_bot_right:\n",
    "                        x_bot_right = new_x_bot_right\n",
    "\n",
    "                    new_y_top_left = cnt[:,0,1].min() \n",
    "                    if new_y_top_left < y_top_left:\n",
    "                        y_top_left = new_y_top_left \n",
    "\n",
    "                    new_y_bot_right = cnt[:,0,1].max()\n",
    "                    if new_y_bot_right > y_bot_right:\n",
    "                        y_bot_right = new_y_bot_right\n",
    "                \n",
    "                cv2.drawContours(fsz_mask, [cnt], -1, (1), -1)\n",
    "               \n",
    "        # save detected mask as a class attribute\n",
    "        self.detected_mask = fsz_mask\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    def insert_logo(self):\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    def __loss(self, y_true, y_pred):\n",
    "        '''\n",
    "        Creating combined BCE and Dice Loss function which we will use in the model\n",
    "        '''\n",
    "        return tf.keras.losses.binary_crossentropy(y_true, y_pred) + self.__dice_loss(y_true, y_pred)\n",
    "    \n",
    "\n",
    "    \n",
    "    def __dice_loss(self, y_true, y_pred):\n",
    "        '''\n",
    "        Creating a Dice Loss function for our model\n",
    "        '''\n",
    "        \n",
    "        numerator = 2 * tf.reduce_sum(y_true * y_pred, axis=(1, 2, 3))\n",
    "        denominator = tf.reduce_sum(y_true + y_pred, axis=(1, 2, 3))\n",
    "        return tf.reshape(1 - numerator / denominator, (-1, 1, 1))\n",
    "    \n",
    "\n",
    "\n",
    "    def __dice_coef(self, y_true, y_pred):\n",
    "        '''\n",
    "        Creating a Dice Coefficient to use it like a metric in our model\n",
    "        '''\n",
    "        numerator = 2 * tf.reduce_sum(y_true * y_pred, axis=-1)\n",
    "        denominator = tf.reduce_sum(y_true + y_pred, axis=-1)\n",
    "        return (numerator + 1) / (denominator + 1)\n",
    "    \n",
    "    \n",
    "    def __optical_flow_point():\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def __predict_full_size(self, img_height, img_width, step=50):\n",
    "        \n",
    "        # getting the frame size\n",
    "        frame_height, frame_width, _ = self.frame.shape\n",
    "        \n",
    "        # create mask for full size i,ahe prediction\n",
    "        fsz_mask = np.zeros((frame_height, frame_width, 1), dtype='float32')\n",
    "\n",
    "        flag_k = False\n",
    "        flag_j = False\n",
    "        \n",
    "        # split up the full frame to smaller images (same than using in model) and predict them\n",
    "        for k in range(0, frame_height, step):\n",
    "            if k + img_height >= (frame_height-1):\n",
    "                k = frame_height - img_height\n",
    "                flag_k = True\n",
    "\n",
    "            for j in range(0, frame_width, step):\n",
    "                if j + img_width >= (frame_width-1):\n",
    "                    j = frame_width - img_width\n",
    "                    flag_j = True\n",
    "                    \n",
    "                mask_cr = fsz_mask[k:k + img_height, j:j + img_width]\n",
    "                frame_cr = frame[k:k + img_height, j:j + img_width]\n",
    "                test_cr = np.expand_dims(frame_cr, axis=0)\n",
    "                cr_predict = self.model.predict(test_cr)\n",
    "            \n",
    "                for y in range(img_height):\n",
    "                    for x in range(img_width):\n",
    "                        if cr_predict[0][y, x] > mask_cr[y, x]:\n",
    "                            mask_cr[y, x] = cr_predict[0][y, x]\n",
    "\n",
    "                if flag_j:\n",
    "                    break\n",
    "\n",
    "            if flag_k:\n",
    "                break\n",
    "     \n",
    "        return fsz_mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
